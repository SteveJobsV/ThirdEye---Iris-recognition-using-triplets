{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import ImageEnhance,ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.layers.core import Lambda\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from keras.activations import relu\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, GlobalAveragePooling2D ,Dense, Concatenate,Conv2DTranspose,Conv2D,Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "\n",
    "# Putting this in for some errors that occur on my setup\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "# np.random.seed(1337) # for reproducibility\n",
    "\n",
    "#Number of classes\n",
    "classes = 293\n",
    "\n",
    "#Length of feature vector\n",
    "FEATURES = 1024\n",
    "\n",
    "#Image dimensions, square images only, can change to non-square\n",
    "imgDimension = 256\n",
    "\n",
    "\n",
    "#Sorting for file reads\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n",
    "    (in degrees). The returned image will be large enough to hold the entire\n",
    "    new image, with a black background, taken from stackoverflow\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the image size\n",
    "    # No that's not an error - NumPy stores image matricies backwards\n",
    "    image_size = (image.shape[1], image.shape[0])\n",
    "    image_center = tuple(np.array(image_size) / 2)\n",
    "\n",
    "    # Convert the OpenCV 3x2 rotation matrix to 3x3\n",
    "    rot_mat = np.vstack(\n",
    "        [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n",
    "    )\n",
    "\n",
    "    rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n",
    "\n",
    "    # Shorthand for below calcs\n",
    "    image_w2 = image_size[0] * 0.5\n",
    "    image_h2 = image_size[1] * 0.5\n",
    "\n",
    "    # Obtain the rotated coordinates of the image corners\n",
    "    rotated_coords = [\n",
    "        (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n",
    "        (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n",
    "    ]\n",
    "\n",
    "    # Find the size of the new image\n",
    "    x_coords = [pt[0] for pt in rotated_coords]\n",
    "    x_pos = [x for x in x_coords if x > 0]\n",
    "    x_neg = [x for x in x_coords if x < 0]\n",
    "\n",
    "    y_coords = [pt[1] for pt in rotated_coords]\n",
    "    y_pos = [y for y in y_coords if y > 0]\n",
    "    y_neg = [y for y in y_coords if y < 0]\n",
    "\n",
    "    right_bound = max(x_pos)\n",
    "    left_bound = min(x_neg)\n",
    "    top_bound = max(y_pos)\n",
    "    bot_bound = min(y_neg)\n",
    "\n",
    "    new_w = int(abs(right_bound - left_bound))\n",
    "    new_h = int(abs(top_bound - bot_bound))\n",
    "\n",
    "    trans_mat = np.matrix([\n",
    "        [1, 0, int(new_w * 0.5 - image_w2)],\n",
    "        [0, 1, int(new_h * 0.5 - image_h2)],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Compute the tranform for the combined rotation and translation\n",
    "    affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n",
    "\n",
    "    # Apply the transform\n",
    "    result = cv2.warpAffine(\n",
    "        image,\n",
    "        affine_mat,\n",
    "        (new_w, new_h),\n",
    "        flags=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    Augment function, needs an image and a augment type integer.\n",
    "'''\n",
    "def augment(im,augType):\n",
    "        if(augType == 0):\n",
    "            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "            im = cv2.filter2D(im, -1, kernel)\n",
    "        if(augType == 1):\n",
    "            im = rotate_image(im,30)\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\n",
    "        if(augType == 2):\n",
    "            im = rotate_image(im,120)\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\n",
    "        if(augType == 3):\n",
    "            im = rotate_image(im,320)\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\n",
    "        if(augType == 4):\n",
    "            im = rotate_image(im,230)\n",
    "            im =cv2.resize(im,(imgDimension,imgDimension))\n",
    "        if(augType == 5):\n",
    "            im = np.flip(im,0)\n",
    "        if(augType == 6):\n",
    "            im = np.flip(im,1)\n",
    "        if(augType == 7):\n",
    "            im[0:70] = 0\n",
    "        if(augType == 8):\n",
    "            cl1 = clahe.apply(im[:,:,0])\n",
    "            cl1[cl1<10] = 0\n",
    "            im[:,:,0] = cl1\n",
    "            im[:,:,1] = cl1\n",
    "            im[:,:,2] = cl1\n",
    "        if (augType == 9):\n",
    "            im = cv2.blur(im, (3,3))\n",
    "        return im\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Keras generator for loading images in a batch hard fashion. Multithreaded by default in keras.\n",
    "    Modeled for a Tensorflow backend. Takes a static string to the dataset location.\n",
    "\"\"\"\n",
    "\n",
    "def customGenerator():\n",
    "    BATCH_SIZE = 12 #Total images in batch, can fit 12 in a GTX 1070 with ResNet 50.\n",
    "    K = 4 #Num of images per class\n",
    "    CLASSES = classes\n",
    "    #Static paths for now\n",
    "#     folderList = sorted(glob.glob('static_path_to_iris_directory'),key=numericalSort)\n",
    "    folderList = sorted(glob.glob('insert_dataset_folder_here'),key=numericalSort)\n",
    "\n",
    "    yConcat = np.zeros(shape = (BATCH_SIZE,1+FEATURES),dtype = np.int32)\n",
    "    \n",
    "    while True:\n",
    "        y2 = np.zeros(shape = (1+FEATURES),dtype = np.int32)\n",
    "        xI = np.zeros(shape = (BATCH_SIZE,3,imgDimension,imgDimension))\n",
    "        numFm = random.sample(range(CLASSES), BATCH_SIZE//K)\n",
    "        for x in range(BATCH_SIZE//K):\n",
    "            imList = glob.glob(folderList[numFm[x]] + \"/*\")\n",
    "            numIm = random.sample(range(len(imList)), K)\n",
    "            #Augmentation, comment out if not needed\n",
    "#             augType = random.sample(range(9), 1)\n",
    "            for i in range(len(numIm)):\n",
    "                im = cv2.imread(imList[numIm[i]])\n",
    "                im = cv2.resize(im,(imgDimension,imgDimension))\n",
    "#                 im= augment(im,augType)\n",
    "                im= np.einsum('lij->jli', im)\n",
    "                xI[i + (x*K)] = im\n",
    "                \n",
    "                yConcat [i + (x*K)] = y2\n",
    "                yConcat [i + (x*K)][-1] = numFm[x]\n",
    "\n",
    "        xI = np.einsum('abcd->acdb',xI)\n",
    "        yield (xI,yConcat)\n",
    "\n",
    "\"\"\"\n",
    "    Batch hard loss implementation from https://omoindrot.github.io/triplet-loss\n",
    "    Modified to use a soft margin.\n",
    "\"\"\"\n",
    "def _get_anchor_positive_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i and j are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "\n",
    "    # Check if labels[i] == labels[j]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    mask = tf.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def batch_hard_triplet_loss(true, pred, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = pred[:,classes:]\n",
    "    labels = true[:,-1]\n",
    "    margin = 0.8\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = tf.to_float(mask_anchor_positive)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = tf.to_float(mask_anchor_negative)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "#     hP = K.max(hardest_positive_dist)\n",
    "#     hN =  K.min(hardest_negative_dist)\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    #Usual batch hard triplet loss:\n",
    "#     triplet_loss = tf.maximum(hP - hN + margin, 0.0)\n",
    "\n",
    "    #Soft-margin triplet loss\n",
    "    triplet_loss = K.log(1.0 + K.exp(hardest_positive_dist - hardest_negative_dist))\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss\n",
    "def batch_all_triplet_loss(true, pred, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "#     print (labels)\n",
    "    embeddings = pred[:,classes:]\n",
    "    labels = true[:,-1]\n",
    "    print (labels)\n",
    "    \n",
    "#     print (embeddings)\n",
    "    margin = 0.5\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.to_float(mask)\n",
    "    triplet_loss = tf.multiply(mask, triplet_loss)\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    triplet_loss = tf.maximum(triplet_loss, 0.0)\n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16))\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\n",
    "\n",
    "    return triplet_loss\n",
    "\n",
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm = tf.diag_part(dot_product)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "#     distances = tf.expand_dims(square_norm, 0) - 2.0 * dot_product + tf.expand_dims(square_norm, 1)\n",
    "    distances =  (dot_product/tf.expand_dims(square_norm, 0)*tf.expand_dims(square_norm, 1))\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = 1-distances\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        distances = distances + mask * 1e-8\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def l2Norm(x):\n",
    "    return  K.l2_normalize(x, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Model generation\"\"\"\n",
    "inp = Input(shape = (3,imgDimension,imgDimension))\n",
    "base_model = ResNet50(weights='imagenet', include_top=False,input_shape=(imgDimension,imgDimension,3))\n",
    "\n",
    "\n",
    "print (\"Loaded initial model\")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "fc2 = Dense(FEATURES,activation = 'relu',name = 'embedding_weights')(x)\n",
    "fc2 = BatchNormalization()(fc2)\n",
    "fc2 = Lambda(lambda x: K.l2_normalize(x, axis=1))(fc2)\n",
    "predictions = Dense(293,name = 'predictions',use_bias = False)(fc2)\n",
    "conc = concatenate([predictions, fc2], name='xF')\n",
    "triplet_model = Model(inputs=base_model.input, outputs=conc)\n",
    "\n",
    "\"\"\"Model generation\"\"\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "filepath=cwd + \"/batchHard_ResNet50-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_predictions_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "print (triplet_model.summary())\n",
    "\n",
    "# triplet_model.load_weights(\"/home/sohaib/Downloads/Features/batchHard_ResNet50-08-0.58.hdf5\",by_name = True)\n",
    "\"\"\"\n",
    "    Training happens here, same training and validation generators due to laziness\n",
    "\"\"\"\n",
    "gen_tr = customGenerator()\n",
    "gen_te = customGenerator()\n",
    "triplet_model.compile(loss=batch_hard_triplet_loss, optimizer=SGD(0.0004))\n",
    "history = triplet_model.fit_generator(gen_tr, \n",
    "                          validation_data=gen_te,  \n",
    "                          epochs=1, \n",
    "                          verbose=1,\n",
    "                          workers=4,\n",
    "                          steps_per_epoch=1000, \n",
    "                          validation_steps=50,callbacks = callbacks_list,use_multiprocessing = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
